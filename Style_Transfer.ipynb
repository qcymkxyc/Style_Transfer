{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-07T11:34:22.829956Z",
     "start_time": "2018-08-07T11:34:16.938925Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing.image import  load_img\n",
    "from keras.preprocessing.image import array_to_img\n",
    "from keras.applications.vgg19 import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-07T11:34:22.856580Z",
     "start_time": "2018-08-07T11:34:22.836960Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import keras\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.utils import plot_model\n",
    "from keras.applications import VGG16\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from scipy import misc\n",
    "\n",
    "def check_img(func):\n",
    "    \"\"\"\n",
    "        图片检验\n",
    "    \"\"\"\n",
    "    def wrapper(obj,img1,img2):\n",
    "        assert img1.shape == img2.shape,\"图片的大小不统一\"\n",
    "        return func(obj,img1,img2)\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "class Transfer(object):\n",
    "    \"\"\"\n",
    "        做风格迁移的类\n",
    "    \"\"\"\n",
    "    def __init__(self,style_image_path,content_image_path,style_weight ,generate_image_shape = None):\n",
    "        \"\"\"\n",
    "            @param style_image_path:    风格图片路径\n",
    "            @param content_image_path:    内容图片路径\n",
    "            @param generate_image_shape:    tuple或list，生成图片的长和宽，默认为内容图片的长和宽\n",
    "            @param style_weight:     dict,{层的名字：权重}风格权重 \n",
    "        \"\"\"\n",
    "        self.style_image_path = style_image_path\n",
    "        self.content_image_path = content_image_path\n",
    "        \n",
    "        self.generate_image_shape = generate_image_shape\n",
    "        \n",
    "        self.style_weight = style_weight\n",
    "\n",
    "        \n",
    "    def init_model(self):\n",
    "        \n",
    "        #获取生成图片的长和宽\n",
    "        n_H,n_W,_ = Transfer.load_img(\n",
    "                                    img_path = self.content_image_path,\n",
    "                                    target_shape = self.generate_image_shape).shape\n",
    "        self.generate_image_shape = n_H,n_W                                     \n",
    "        \n",
    "        #得到输入图片\n",
    "        content_img = Transfer.load_img(img_path =  self.content_image_path,target_shape = self.generate_image_shape) \n",
    "        style_img = Transfer.load_img(img_path = self.style_image_path,target_shape = self.generate_image_shape)\n",
    "#         generated_img = K.placeholder(self.__add_img_noise(content_img),name = \"generated_img\")\n",
    "        \n",
    "        #合成模型输入张量\n",
    "        content_img = K.expand_dims(content_img,axis = 0)\n",
    "        style_img = K.expand_dims(style_img,axis = 0)\n",
    "#         generated_img = K.expand_dims(generated_img,axis = 0)\n",
    "        combine_img = K.concatenate([content_img,style_img], axis = 0)\n",
    "        \n",
    "        #载入预训练模型\n",
    "        self.model = VGG16(include_top = False,input_tensor = combine_img)\n",
    "        \n",
    "        self.layers = dict()\n",
    "        for layer in vgg_model.layers:\n",
    "            self.layers[layer.name] = layer.output\n",
    "        with K.get_session() as session:\n",
    "            session.runs\n",
    "        session.run(d[\"block5_conv3\"])\n",
    "#         plot_model(vgg_model,\"model.png\", show_shapes = True, show_layer_names = True)\n",
    "#         K.get_session().run(vgg_model)\n",
    "\n",
    "    \n",
    "    @check_img\n",
    "    def __style_layer_loss(self,style_image,generate_image):\n",
    "        \"\"\"\n",
    "            计算单层的风格loss\n",
    "            @param style_image:    风格图片\n",
    "            @param generate_image:    生成的图片\n",
    "            @return: 风格loss\n",
    "            \n",
    "        \"\"\"\n",
    "        def compute_style_matrix(image):\n",
    "            \"\"\"\n",
    "                计算图片的风格矩阵\n",
    "            \"\"\"\n",
    "            n_H,n_W,n_C = image.shape\n",
    "            re_image = K.reshape(x = image,shape = (n_H * n_W,n_C))\n",
    "            return K.dot(K.transpose(re_image), re_image)\n",
    "        \n",
    "        n_H,n_W,n_C = style_image.shape\n",
    "        \n",
    "        #计算风格矩阵\n",
    "        style_matrix = compute_style_matrix(style_image)\n",
    "        generate_matrix = compute_style_matrix(generate_image)\n",
    "        \n",
    "#         return K.sum(K.square(style_matrix - generate_matrix)) / 4. * K.flK.square(n_H * n_W * n_C)\n",
    "#TODO\n",
    "        return K.sum(K.square(style_matrix - generate_matrix))\n",
    "    \n",
    "    def __style_loss(self,layer_weight,model):\n",
    "        \"\"\"\n",
    "            计算总的风格loss\n",
    "            @param layer_weight:    dict类型，格式为：{\"层的名字\":层的权重}\n",
    "            @param model:    模型\n",
    "        \"\"\"\n",
    "        #获取模型的层数\n",
    "        layer_dict = {layer.name : layer.output for layer in model.layers}\n",
    "        #检查层名是否正确\n",
    "        assert set(layer_weight.keys()).issubset(layer_dict.keys()),\"层名不匹配\"\n",
    "        \n",
    "        self.layers = dict()\n",
    "        for layer in self.model.layers:\n",
    "            self.layers[layer.name] = layer.output\n",
    "\n",
    "        style_loss = 0.\n",
    "        for layer_name,weight in self.style_weight.items():\n",
    "            output_img = self.layers[layer_name]\n",
    "            style_arr = output_img[1,:,:,:]\n",
    "            generate_arr = output_img[-1,:,:,:]  \n",
    "            style_loss += weight * self.__style_layer_loss(style_arr, generate_arr)\n",
    "            \n",
    "            \n",
    "        return style_loss                  \n",
    "        \n",
    "    def __add_img_noise(self,img,noise_rate = 0.6):\n",
    "        \"\"\"\n",
    "            给图片添加噪声\n",
    "            @param img: 原图片 \n",
    "        \"\"\"\n",
    "        random_noise = np.random.uniform(low = -20. ,high = 20.,size = img.shape).astype(\"float32\")\n",
    "        return  (random_noise * noise_rate + img * (1 - noise_rate)) / 255.\n",
    "    \n",
    "    @check_img\n",
    "    def __content_loss(self,content_image,generate_image):\n",
    "        \"\"\"\n",
    "            计算内容loss\n",
    "            @param content_image:    内容图片\n",
    "            @param generate_image:    生成图片\n",
    "            @return:    内容loss\n",
    "        \"\"\"\n",
    "        return K.mean(K.square(content_image - generate_image)) / 4\n",
    "    \n",
    "    def __total_loss(self,style_loss,content_loss,alpha = 10,beta = 40):\n",
    "        \"\"\"\n",
    "            计算总体loss\n",
    "            @param style_loss:    风格loss\n",
    "            @param content_loss:    内容loss\n",
    "            @param alpha,beta:    内容loss和风格loss的比例    \n",
    "            @return: 总体的loss\n",
    "        \"\"\"\n",
    "        return alpha * content_loss + beta * style_loss\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_img(img_path,target_shape):\n",
    "        \"\"\"\n",
    "            载入图片\n",
    "            @param img_path:    图片路径\n",
    "            @param target_shape:    生成图片的长和宽\n",
    "            @return: 图片的array形式\n",
    "        \"\"\"\n",
    "        img = load_img(path = img_path,target_size = target_shape)\n",
    "        img = img_to_array(img,\"channels_last\")\n",
    "        return img\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_img(img,path):\n",
    "        \"\"\"\n",
    "            保存图片\n",
    "            @param img: 图片\n",
    "            @param path:     保存路径\n",
    "        \"\"\"\n",
    "        path_name,_ = os.path.split(path)\n",
    "        if not os.path.exists(path_name):\n",
    "            os.mkdir(path_name)\n",
    "        misc.imsave(path,img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-07T11:34:23.081718Z",
     "start_time": "2018-08-07T11:34:22.865134Z"
    }
   },
   "outputs": [],
   "source": [
    "pic_path = \"./test.png\" \n",
    "\n",
    "style_weight = {\n",
    "    \"block1_conv1\" : 0.2,\n",
    "    \"block2_conv1\" : 0.2,\n",
    "    \"block3_conv1\" : 0.2,\n",
    "    \"block4_conv1\" : 0.2,\n",
    "    \"block5_conv1\" : 0.2\n",
    "}\n",
    "\n",
    "t = Transfer(content_image_path = pic_path,style_image_path = pic_path,style_weight = style_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-07T11:34:50.341636Z",
     "start_time": "2018-08-07T11:34:30.029862Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-fff4e971ac1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-47a04971c0c7>\u001b[0m in \u001b[0;36minit_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0ml_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvgg_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"block5_conv3\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;31m#         plot_model(vgg_model,\"model.png\", show_shapes = True, show_layer_names = True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;31m#         K.get_session().run(vgg_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "t.init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
